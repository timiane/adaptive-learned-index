{"activation": "sigmoid", "activation_last": "relu", "batch_size": 316, "layer_nodes": 16, "lr": 0.1, "patience": 50}