{"activation": "relu", "activation_last": "linear", "batch_size": 304, "layer_nodes": 32, "lr": 0.1, "patience": 50}