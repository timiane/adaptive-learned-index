{"activation": "relu", "activation_last": "sigmoid", "batch_size": 353, "layer_nodes": 16, "lr": 0.01, "patience": 50}