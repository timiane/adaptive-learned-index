{"activation": "linear", "activation_last": "relu", "batch_size": 348, "layer_nodes": 32, "lr": 0.01, "patience": 50}